{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "Intel Corporation Interactive Event Analysis\n",
    "=========================================\n",
    "\n",
    "This interactive notebook can be used for exploring events generated by Vertex.AI components.\n",
    "\n",
    "To use it, you'll first need to produce an event log.  The way you do this varies with the various components (since they're configured in different ways).\n",
    "\n",
    "* With the Tile server, you'll want to add something like the following stanza to your JSON _server.conf_:\n",
    "\n",
    "      \"eventlog\": {\n",
    "        \"@type\": \"type.vertex.ai/vertexai.eventing.file.proto.EventLog\",\n",
    "        \"filename\": \"eventlog.gz\"\n",
    "       },\n",
    "       \"event_tracking_mode\": \"EVENT_TRACKING_MODE_GLOBAL\"\n",
    "     \n",
    "  When run with this configuration, the server will write a file, _eventlog.gz_, on shutdown (which you can trigger with a Ctrl-C).\n",
    "\n",
    "     \n",
    "* With the PlaidML Python backends, you can typically set an environment variable:\n",
    "\n",
    "       PLAIDML_EVENTLOG_FILENAME=eventlog.gz\n",
    "     \n",
    "  This will cause events to be logged to _eventlog.gz_ on shutdown.\n",
    "\n",
    "Next, run this notebook with:\n",
    "\n",
    "    ./t2 run //tools/analysis\n",
    "    \n",
    "By default, the notebook will look for _eventlog.gz_ in your home directory.  If that's wrong, you can pass a filename like so:\n",
    "\n",
    "    ./t2 run //tools/analysis -- /path/to/eventlog.gz\n",
    "    \n",
    "Once the notebook is up and running you can start adding your own cells to explore the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Add some useful imports, &c.\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "if platform.system() != 'Windows':\n",
    "    ta_dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "    if ta_dir not in sys.path:\n",
    "        sys.path.insert(1, ta_dir)\n",
    "\n",
    "import bokeh.io as bi\n",
    "import bokeh.models as bm\n",
    "import bokeh.plotting as bp\n",
    "import bokeh.palettes as bpa\n",
    "import bokeh.transform as bt\n",
    "from collections import defaultdict, namedtuple\n",
    "import datetime\n",
    "import functools\n",
    "import graphviz\n",
    "import humanize\n",
    "import imp\n",
    "import IPython.display\n",
    "from IPython.display import display_svg\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pygments import highlight\n",
    "from pygments.lexers.c_cpp import CLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "\n",
    "bi.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With the Python path configured, the Bazel-built code can be loaded.\n",
    "import tools.analysis as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the raw events, and make them useful.\n",
    "scope = ta.Scope()\n",
    "scope.read_eventlog(os.getenv('PLAIDML_EVENTLOG_FILENAME'))\n",
    "acts = ta.as_dataframe(scope, scope.activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's build up some stats on the kernels:\n",
    "execs = acts[acts.verb.isin(ta.VERBS_EXECUTING)]\n",
    "halinfos = execs.activity.apply(lambda d: scope.get_activity(d, d.ocl_runinfo.kernel_id).ocl_kernelinfo)\n",
    "groups = pd.DataFrame({\n",
    "    'halinfo': halinfos,\n",
    "    'runtime': execs.end - execs.start,\n",
    "    'kname': halinfos.apply(lambda i: i.kname),\n",
    "    'activity': execs.activity.apply(lambda d: scope.get_activity(d, d.ocl_runinfo.kernel_id)),\n",
    "}).groupby('kname')\n",
    "kernels = groups.mean()\n",
    "halinfos = groups.first().loc[:, 'halinfo']\n",
    "kernels.sort_values(by='runtime', ascending=False, inplace=True)\n",
    "total = np.sum(kernels.runtime)\n",
    "\n",
    "kernels = kernels.assign(\n",
    "    halinfo=halinfos,\n",
    "    activity=groups.first().loc[:, 'activity'],\n",
    "    compilation=groups.first().loc[:, 'activity'].apply(lambda a: a.hal_compilationinfo),\n",
    "    build=groups.first().loc[:, 'activity'].apply(lambda a: a.ocl_buildinfo),\n",
    "    c_runtime=kernels.runtime.cumsum(),\n",
    "    percentage=kernels.runtime / total,\n",
    "    gflops=halinfos.apply(lambda x: x.kinfo.flops) / kernels.runtime,\n",
    "    io=halinfos.apply(lambda x: x.kinfo.bytes) / kernels.runtime,\n",
    "    vec_sizes=halinfos.apply(lambda x: x.kinfo.contraction.vec),\n",
    "    offsets=halinfos.apply(lambda x: x.kinfo.contraction.off),\n",
    "    accesses=halinfos.apply(lambda x: [(a.name, a.range, '.'.join(str(s) for s in a.strides)) for a in x.kinfo.contraction.accesses]),\n",
    "    constraints=halinfos.apply(lambda x: ['{} <= {}'.format('+'.join(['{}*{}'.format(v, x.kinfo.contraction.accesses[i].name) for i, v in enumerate(c.lhs) if v != 0]),\n",
    "                                                            c.rhs) for c in x.kinfo.contraction.constraints])\n",
    ")\n",
    "\n",
    "kernels = kernels.assign(c_percentage=kernels.percentage.cumsum())\n",
    "\n",
    "kernels_fmt = {\n",
    "    'gflops': lambda x: humanize.naturalsize(x, gnu=True, format='%.1f ') + 'F/s',\n",
    "    'io': lambda x: humanize.naturalsize(x) + '/s',\n",
    "    'percentage': lambda x: '{:.2f}%'.format(100*x),\n",
    "    'c_percentage': lambda x: '{:.2f}%'.format(100*x),\n",
    "    'runtime': lambda x: datetime.timedelta(seconds=x),\n",
    "    'c_runtime': lambda x: datetime.timedelta(seconds=x),\n",
    "    'accesses': lambda x: ' --- '.join(['{} : {}[{}]'.format(*a) for a in x]),\n",
    "    'constraints': lambda x: ', '.join(x)\n",
    "}\n",
    "\n",
    "# Browser-side copy of the kernels DataFrame.  N.B. This must only contain serializable data.\n",
    "kernels_source = bm.ColumnDataSource(kernels[['c_runtime', 'c_percentage', 'gflops', 'io', 'percentage', 'runtime']])\n",
    "\n",
    "# The default tooltip to use when displaying kernels graphically.\n",
    "kernels_hover = bm.HoverTool(tooltips=[\n",
    "    ('kernel', '@kname'),\n",
    "    ('knum', '$index'),\n",
    "    ('gflops', '@gflops'),\n",
    "    ('GB/s', '@io'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's display mean OpenCL kernel execution times, because they're often interesting.\n",
    "kernels[['runtime', 'c_runtime', 'percentage', 'c_percentage', 'gflops', 'io']].style.format(kernels_fmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here's a graph of the kernels.  Note the knum is ordered by highest runtime.\n",
    "p = bp.figure(title = 'Kernel Performance', plot_width=760, plot_height=800)\n",
    "p.add_tools(kernels_hover)\n",
    "p.xaxis.axis_label = 'GFlops'\n",
    "p.yaxis.axis_label = 'GB/s'\n",
    "\n",
    "circle_size_transform = bm.transforms.CustomJSTransform(\n",
    "    func='return (x) * 2000',\n",
    "    v_func = '''\n",
    "      new_xs = new Array(xs.length)\n",
    "      for(i = 0; i < xs.length; i++) {\n",
    "        new_xs[i] = xs[i] * 2000\n",
    "      }\n",
    "      return new_xs''')\n",
    "\n",
    "p.circle(x='gflops', y='io', fill_alpha=0.2, size=bt.transform('percentage', circle_size_transform),\n",
    "         source=kernels_source)\n",
    "\n",
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can also view the mean kernel execution times as a bar graph.\n",
    "p = bp.figure(title = 'Kernel Mean Runtimes',\n",
    "              plot_width=760, plot_height=kernels.shape[0]*12,\n",
    "              x_range=(0., kernels.iloc[0].runtime * (1.15 + kernels.iloc[0].c_percentage)),\n",
    "              y_range=kernels.iloc[::-1].index.values,\n",
    "              x_axis_location='above')\n",
    "p.extra_x_ranges = {'Percent': bm.ranges.DataRange1d(flipped=True)}\n",
    "p.add_tools(kernels_hover)\n",
    "p.xaxis.axis_label = 'Mean Runtime (s)'\n",
    "p.xaxis.formatter = bm.formatters.NumeralTickFormatter(format='0.000000')\n",
    "p.yaxis.axis_label = 'Kernel'\n",
    "p.add_layout(bm.axes.LinearAxis(x_range_name='Percent', axis_label='Cumulative Percentage',\n",
    "                                formatter=bm.formatters.NumeralTickFormatter(format='0%')), 'above')\n",
    "\n",
    "p.hbar(y='kname', height=1, left=0, right='runtime', fill_alpha=0.2, source=kernels_source)\n",
    "\n",
    "p.hbar(y='kname', height=1, left=0, right='c_percentage', fill_alpha=0.2,\n",
    "       fill_color='green', line_color='green', x_range_name='Percent', source=kernels_source)\n",
    "\n",
    "bp.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here's a kernel source viewer.  We order the kernels greatest-runtime-first, since that's usually\n",
    "# what's most interesting.\n",
    "\n",
    "def KernelWidget(krow):\n",
    "    (halinfo, runtime, accesses, constraints) = krow[['halinfo', 'runtime', 'accesses', 'constraints']]\n",
    "    code = \"\"\"\n",
    "// Kernel: {}\n",
    "// Mean Runtime: {}\n",
    "// Operations:{}\n",
    "// Accesses:{}\n",
    "// Constraints:{}\n",
    "//\n",
    "{}\n",
    "\"\"\".format(halinfo.kname, datetime.timedelta(seconds=runtime),\n",
    "           ''.join(['\\n//   {}'.format(op) for op in halinfo.kinfo.contraction.ops]),\n",
    "           ''.join(['\\n//   {} range={} strides=[{}]'.format(*a) for a in accesses]),\n",
    "           ''.join(['\\n//   {}'.format(c) for c in constraints]),\n",
    "           halinfo.src)\n",
    "    html = highlight(code, CLexer(), HtmlFormatter(full=True))\n",
    "    return widgets.HTML(html, layout=widgets.Layout(width='100%', height='500px'))\n",
    "\n",
    "@interact(knum=widgets.IntSlider(min=0, max=kernels.shape[0]-1, continuous_update=False))\n",
    "def src(knum=0):\n",
    "    return KernelWidget(kernels.iloc[knum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here's the program of the highest-runtime kernel:\n",
    "kernel = kernels.iloc[0]\n",
    "kname = kernel.halinfo.kname\n",
    "total = 0\n",
    "for size, count in kernel.compilation.alloc_sizes.items():\n",
    "    total += size*count\n",
    "print('Kernel {}\\'s program uses {} of temporary memory.\\n'.format(kname, humanize.naturalsize(total, binary=True)))\n",
    "print(kernel['compilation'].program.code)\n",
    "\n",
    "# N.B. If you want memory details, you can do something like this:\n",
    "# for size, count in kernel.compilation.alloc_sizes.items():\n",
    "#     print('  {} alloc(s) of size {}'.format(count, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here's the device for that longest-running kernel:\n",
    "kact = kernels.iloc[0].activity\n",
    "scope.get_activity(kact, kact.ocl_buildinfo.device_id).ocl_deviceinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# And the plaform for that device:\n",
    "kact = kernels.iloc[0].activity\n",
    "dact = scope.get_activity(kact, kact.ocl_buildinfo.device_id)\n",
    "scope.get_activity(dact, dact.ocl_deviceinfo.platform_id).ocl_platforminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Here's a network view of the static computation schedule for the longest-running kernel's program.\n",
    "#\n",
    "# Unfortunately, the static computation schedule for even a simple network can be rather large.\n",
    "# So: this implementation constructs subgraphs of a particular radius around nodes of interest,\n",
    "# and visualizes the subgraphs.\n",
    "\n",
    "# Build the overall computation graph, using networkx.\n",
    "kact = kernels.iloc[0].activity\n",
    "spb = kact.lpt_schedule\n",
    "sched = nx.DiGraph()\n",
    "\n",
    "nidx_iter = itertools.count(1)\n",
    "aidx_nidx = {}\n",
    "sidx_nidx = {}\n",
    "first_use = {}\n",
    "\n",
    "def add_alloc(aidx, alloc=None):\n",
    "    if not alloc:\n",
    "        alloc = spb.allocs[aidx]\n",
    "    label='a{}'.format(aidx)\n",
    "    if alloc.input:\n",
    "        label = label + ' input:' + alloc.input\n",
    "    if alloc.output:\n",
    "        label = label + ' output:' + alloc.output\n",
    "    nidx = next(nidx_iter)\n",
    "    aidx_nidx[aidx] = nidx\n",
    "    sched.add_node(nidx, label=label, shape='box')\n",
    "    return nidx\n",
    "\n",
    "for aidx, alloc in enumerate(spb.allocs):\n",
    "    add_alloc(aidx, alloc)\n",
    "\n",
    "for sidx, step in enumerate(spb.steps):\n",
    "    nidx = next(nidx_iter)\n",
    "    sidx_nidx[sidx] = nidx\n",
    "    if step.HasField('run'):\n",
    "        kname = spb.knames[step.run.kidx]\n",
    "        if not kname in first_use:\n",
    "            first_use[kname] = sidx\n",
    "    sched.add_node(nidx, shape='ellipse', label='s{}'.format(sidx))\n",
    "    for aidx in step.run.input_aidxs:\n",
    "        sched.add_edge(aidx_nidx[aidx], nidx)\n",
    "    for aidx in step.run.output_aidxs:\n",
    "        sched.add_edge(nidx, add_alloc(aidx))\n",
    "\n",
    "def visualize_subgraph(radius=3, sidx=0):\n",
    "    # Extract the desired subgraph, and render it with graphviz.\n",
    "    subg = nx.ego_graph(sched, sidx_nidx[sidx], radius=radius+1, undirected=True)\n",
    "    vizg = nx.ego_graph(sched, sidx_nidx[sidx], radius=radius, undirected=True)\n",
    "    viz = graphviz.Digraph(graph_attr={'dpi': '56'})\n",
    "    incoming = set()\n",
    "    outgoing = set()\n",
    "    for u, v in subg.edges:\n",
    "        viz.edge('n{}'.format(u), 'n{}'.format(v))\n",
    "        incoming.add(u)\n",
    "        outgoing.add(v)\n",
    "    internal = incoming.intersection(outgoing)\n",
    "    for nidx, ndata in subg.nodes.items():\n",
    "        if nidx not in vizg.nodes and nidx not in internal:\n",
    "            shape = 'point'\n",
    "        else:\n",
    "            shape = ndata['shape']\n",
    "        viz.node('n{}'.format(nidx), ndata['label'], shape=shape)\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "        try:\n",
    "            display_svg(viz._repr_svg_(), raw=True)        \n",
    "        except graphviz.ExecutableNotFound as not_found:\n",
    "            return not_found\n",
    "    w = [out]\n",
    "    if spb.steps[sidx].HasField('run'):\n",
    "        kname = spb.knames[spb.steps[sidx].run.kidx]\n",
    "        w.append(widgets.Label('Step {0} => {1}, first used by step {2}'.format(sidx, kname, first_use[kname])))\n",
    "        w.append(KernelWidget(kernels.loc[kname]))\n",
    "    return widgets.VBox(w)\n",
    "\n",
    "interact(visualize_subgraph,\n",
    "         radius=widgets.IntSlider(value=2, min=1, max=20, continuous_update=False),\n",
    "         sidx=widgets.BoundedIntText(value=0, min=0, max=len(spb.steps)-1,\n",
    "                                     continuous_update=False,\n",
    "                                     description='Step[0..{}] '.format(len(spb.steps)-1)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the invocations.  It can be useful to compare the sum\n",
    "# kernel execution time to the end-to-end kernel execution time:\n",
    "invocations = acts[acts.verb == 'plaidml::invoker::ScheduleInvocation']\n",
    "\n",
    "def kernel_stats(row):\n",
    "    inv = row.activity\n",
    "    execs = ta.as_dataframe(scope, filter(lambda act: act.verb in ta.VERBS_EXECUTING, inv.subtree()))\n",
    "    execs = execs.assign(delta=execs.end-execs.start)\n",
    "    aggs = execs.agg({'start': np.min, 'end': np.max, 'delta': np.sum})\n",
    "    overall_time = aggs.end - aggs.start\n",
    "    row = row.drop('parent')\n",
    "    return row.append(pd.Series([execs.size, overall_time, aggs.delta, aggs.delta/overall_time],\n",
    "                                index=['kernels', 'kernel_walltime', 'kernel_exectime', 'load']))\n",
    "\n",
    "invocations = invocations.apply(kernel_stats, axis='columns').sort_values(by=['kernels', 'load'], ascending=False)\n",
    "invocations[['verb', 'kernels', 'start', 'end', 'kernel_walltime', 'kernel_exectime', 'load']].style.format({\n",
    "    'kernel_walltime': lambda x: datetime.timedelta(seconds=x),\n",
    "    'kernel_exectime': lambda x: datetime.timedelta(seconds=x),\n",
    "    'start': lambda x: datetime.timedelta(seconds=x),\n",
    "    'end': lambda x: datetime.timedelta(seconds=x),\n",
    "    'load': lambda x: '{:.2f}%'.format(100*x),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# It can also be interesting to look at what happens across an entire batch invocation.\n",
    "\n",
    "# Let's pick the last of the invocations with the most kernels -- that's usually what we're interested in:\n",
    "inv = invocations[invocations.kernels == invocations.iloc[0].kernels].sort_values(by='start', ascending=False).iloc[0]\n",
    "\n",
    "# Add in all current-buffer mapping events that start after the start of this invocation and before the next.\n",
    "# (Not that there will typically be a next invocation.)\n",
    "next_invs = invocations[inv.start < invocations.start].sort_values(by='start')\n",
    "current_mask = (acts.verb == 'tile::MapCurrent') & (inv.start < acts.start)\n",
    "if next_invs.shape[0]:\n",
    "    current_mask = current_mask & (acts.start < next_invs.iloc[0].start)\n",
    "\n",
    "# Add in all discard-buffer mapping events that start before the start of this invocation and after the previous.\n",
    "prev_invs = invocations[invocations.start < inv.start].sort_values(by='start')\n",
    "\n",
    "discard_mask = (acts.verb == 'vertexai::DiscardCurrent') & (acts.start < inv.start)\n",
    "if prev_invs.shape[0]:\n",
    "    discard_mask = discard_mask & (prev_invs.iloc[-1].start < acts.start)\n",
    "    \n",
    "mask = current_mask | discard_mask\n",
    "\n",
    "# Build up the run.\n",
    "run = ta.as_dataframe(scope, itertools.chain.from_iterable([a.subtree() for a in ([inv.activity] + list(acts[mask].activity.values))]))\n",
    "run = run.assign(name=run.index.astype(str)+'/'+run.verb.apply(lambda s: s.rsplit('::', 1)[-1]))\n",
    "run.update(run[['start', 'end']] - run.start.min())\n",
    "             \n",
    "# Rewrite some acts to have their parent's name, reducing the complexity of the output graph.\n",
    "reparent = run[run.verb.isin(['tile::hal::opencl::HostQueue', 'tile::hal::opencl::DevQueue', 'tile::hal::opencl::Executing', 'tile::hal::opencl::Buffer::Unmap'])]\n",
    "run.update(pd.merge(run, reparent, left_index=True, right_on='parent').name_x.rename('name'))\n",
    "\n",
    "knames = pd.concat([acts.parent, run[run.verb.isin(ta.VERBS_EXECUTING)].activity.apply(\n",
    "    lambda d: scope.get_activity(d, d.ocl_runinfo.kernel_id).ocl_kernelinfo.kname).rename('kname')], axis=1)\n",
    "knames = knames.dropna().set_index(keys='parent')\n",
    "run = pd.merge(run, knames, left_on='parent', right_index=True, how='outer')\n",
    "run = run.assign(kname=run.kname.combine_first(knames.kname))\n",
    "run = run.sort_values(by='start')\n",
    "run_source = bm.ColumnDataSource(run[['verb', 'start', 'end', 'name', 'kname']])\n",
    "\n",
    "# And plot them.\n",
    "verb_cmap = bt.factor_cmap('verb', palette=bpa.Category20[20], factors=sorted(run.verb.unique()))\n",
    "y_range=run.name.drop_duplicates()[::-1].values\n",
    "p = bp.figure(y_range=y_range,\n",
    "              plot_height=800,\n",
    "              plot_width=800,\n",
    "              title='Invocation Gantt',\n",
    "              x_axis_location='above')\n",
    "p.add_tools(bm.HoverTool(\n",
    "    tooltips=[\n",
    "        ('action', '@verb'),\n",
    "        ('kname', '@kname'),\n",
    "        ('start', '@start{0.000000}'),\n",
    "        ('end', '@end{0.000000}')\n",
    "    ]))\n",
    "p.hbar(y='name', left='start', right='end', height=1, source=run_source, fill_alpha=0.2, fill_color=verb_cmap)\n",
    "\n",
    "p.ygrid.grid_line_color = None\n",
    "p.xaxis.axis_label = 'Time (seconds)'\n",
    "p.xaxis.formatter = bm.formatters.NumeralTickFormatter(format='0.000000')\n",
    "p.outline_line_color = None\n",
    "\n",
    "bp.show(p)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
